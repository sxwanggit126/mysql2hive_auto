# MySQL
#db1.default.driver="com.mysql.jdbc.Driver"
#db1.default.url="jdbc:mysql://mysql57.rdsm7gwoyphq7s0.rds.su.baidubce.com:3306/k11_rec_gl?characterEncoding=utf-8"
#db1.default.user="k11_rec_gl"
#db1.default.password="NfD^41N1nfa@!"
#db1.default.dbtable="event"
#db1.default.dbase="k11_rec_gl"
#db1.default.host="mysql57.rdsm7gwoyphq7s0.rds.su.baidubce.com"

#db1.default.driver="com.mysql.jdbc.Driver"
#db1.default.url="jdbc:mysql://bj-spark001.aibee.cn:3306/test?characterEncoding=utf-8"
#db1.default.user="root"
#db1.default.password="123456"
#db1.default.dbtable="student"
#db1.default.dbase="test"
#db1.default.host="bj-spark011.aibee.cn"

#Mysql-scalikjdbc
db.default.driver="com.mysql.jdbc.Driver"
db.default.url="jdbc:mysql://bj-spark001.aibee.cn:3306/mysql2hivemeta?characterEncoding=utf-8"
db.default.user="root"
db.default.password="123456"

#Hive
#h2.default.dbase="test"
#h2.default.dbtable="event_info"
#h2.default.partition.doornot="do"
#h2.default.partition.choose="add"
#h2.default.partition.notadd.column="open_id"
#h2.default.partition.add.column="update_time"
#h2.default.partition.column.union="false"


#spark-conf
spark.default.partition="hive.exec.dynamic.partition"
spark.default.mode="mode"
spark.default.master="local[2]"
spark.default.write.partition="16"